
reading train images...
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 993910.90it/s]
 27%|██████████████████████████████▌                                                                                  | 27/100 [00:01<00:05, 12.25it/s]
preprocessing train volumes...


 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 94/100 [00:05<00:00, 21.75it/s]
padding train volumes...
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 16.08it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 195.73it/s]



































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37it/s]
  0%|                                                                                                                          | 0/100 [00:00<?, ?it/s]

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 49.64it/s]
done creating train dataset
reading validation images...
preprocessing validation volumes...
cropping validation volumes...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 166440.63it/s]
 40%|██████████████████████████████████████████████                                                                     | 4/10 [00:00<00:00, 10.51it/s]
padding validation volumes...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 13.97it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 351.86it/s]



 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 9/10 [00:07<00:00,  1.57it/s]
normalizing validation volumes...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.20it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 45.26it/s]
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='ddp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='ddp')` instead.
  rank_zero_deprecation(
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Epoch 0:   3%|███▏                                                                                         | 8/232 [00:01<00:47,  4.70it/s, loss=0.966]
   | Name       | Type            | Params
------------------------------------------------
0  | encoder1   | Sequential      | 10.2 K
1  | pool1      | MaxPool2d       | 0
2  | encoder2   | Sequential      | 55.6 K
3  | pool2      | MaxPool2d       | 0
4  | encoder3   | Sequential      | 221 K
5  | pool3      | MaxPool2d       | 0
6  | encoder4   | Sequential      | 885 K
7  | pool4      | MaxPool2d       | 0
8  | bottleneck | Sequential      | 3.5 M
9  | upconv4    | ConvTranspose2d | 524 K
10 | decoder4   | Sequential      | 1.8 M
11 | upconv3    | ConvTranspose2d | 131 K
12 | decoder3   | Sequential      | 442 K
13 | upconv2    | ConvTranspose2d | 32.8 K
14 | decoder2   | Sequential      | 110 K
15 | upconv1    | ConvTranspose2d | 8.2 K
16 | decoder1   | Sequential      | 27.8 K
17 | conv       | Conv2d          | 33
------------------------------------------------
7.8 M     Trainable params
0         Non-trainable params
7.8 M     Total params
31.052    Total estimated model params size (MB)
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /mnt/nfs/rdata02-users/users/makaroff/UNet_pytorch/None/version_None/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(














Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████| 232/232 [00:29<00:00,  7.90it/s, loss=0.932, v_num=5yul]
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.




























Epoch 2:  93%|█████████████████████████████████████████████████████████████████████████▏     | 215/232 [00:28<00:02,  7.66it/s, loss=0.868, v_num=5yul]














Epoch 3:  97%|████████████████████████████████████████████████████████████████████████████▌  | 225/232 [00:28<00:00,  7.90it/s, loss=0.839, v_num=5yul]


























































Epoch 7:  97%|████████████████████████████████████████████████████████████████████████████▌  | 225/232 [00:28<00:00,  7.90it/s, loss=0.433, v_num=5yul]














Epoch 8:  99%|██████████████████████████████████████████████████████████████████████████████▎| 230/232 [00:28<00:00,  8.08it/s, loss=0.304, v_num=5yul]


























































Epoch 12:  99%|█████████████████████████████████████████████████████████████████████████████▎| 230/232 [00:28<00:00,  8.02it/s, loss=0.234, v_num=5yul]




































































































































Epoch 21:  91%|██████████████████████████████████████████████████████████████████████▌       | 210/232 [00:28<00:02,  7.45it/s, loss=0.158, v_num=5yul]














Epoch 22:  95%|█████████████████████████████████████████████████████████████████████████▉    | 220/232 [00:28<00:01,  7.70it/s, loss=0.173, v_num=5yul]









































































Epoch 27:  93%|████████████████████████████████████████████████████████████████████████▎     | 215/232 [00:28<00:02,  7.58it/s, loss=0.156, v_num=5yul]


Epoch 28:   6%|█████                                                                          | 15/232 [00:02<00:36,  6.00it/s, loss=0.191, v_num=5yul]
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
