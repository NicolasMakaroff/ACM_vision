
reading train images...
preprocessing train volumes...
cropping train volumes...
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1005828.30it/s]


 85%|████████████████████████████████████████████████████████████████████████████████████████████████                 | 85/100 [00:05<00:00, 22.16it/s]
padding train volumes...
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 16.19it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 202.35it/s]




































 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 99/100 [01:11<00:00,  1.08it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37it/s]
 69%|█████████████████████████████████████████████████████████████████████████████▉                                   | 69/100 [00:01<00:00, 42.32it/s]
done creating train dataset

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 50.19it/s]
preprocessing validation volumes...
cropping validation volumes...
padding validation volumes...
resizing validation volumes...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 186413.51it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 14.00it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 360.54it/s]



 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 8/10 [00:06<00:01,  1.49it/s]
normalizing validation volumes...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.20it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 45.64it/s]
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='ddp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='ddp')` instead.
  rank_zero_deprecation(
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------
Validation sanity check:   0%|                                                                                                   | 0/2 [00:00<?, ?it/s]torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
Epoch 0:   2%|█▌                                                                                           | 4/232 [00:01<01:08,  3.32it/s, loss=0.973]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
   | Name       | Type            | Params
------------------------------------------------
0  | encoder1   | Sequential      | 10.2 K
1  | pool1      | MaxPool2d       | 0
2  | encoder2   | Sequential      | 55.6 K
3  | pool2      | MaxPool2d       | 0
4  | encoder3   | Sequential      | 221 K
5  | pool3      | MaxPool2d       | 0
6  | encoder4   | Sequential      | 885 K
7  | pool4      | MaxPool2d       | 0
8  | bottleneck | Sequential      | 3.5 M
9  | upconv4    | ConvTranspose2d | 524 K
10 | decoder4   | Sequential      | 1.8 M
11 | upconv3    | ConvTranspose2d | 131 K
12 | decoder3   | Sequential      | 442 K
13 | upconv2    | ConvTranspose2d | 32.8 K
14 | decoder2   | Sequential      | 110 K
15 | upconv1    | ConvTranspose2d | 8.2 K
16 | decoder1   | Sequential      | 27.8 K
17 | conv       | Conv2d          | 33
------------------------------------------------
7.8 M     Trainable params
0         Non-trainable params
7.8 M     Total params
31.052    Total estimated model params size (MB)
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /mnt/nfs/rdata02-users/users/makaroff/UNet_pytorch/None/version_None/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(













Epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████▌| 231/232 [00:29<00:00,  7.95it/s, loss=0.922]torch.Size([3, 64, 64])
torch.Size([3, 64, 64])███████████████████████████████████████████████████████████████████████████████████▎            | 21/24 [00:00<00:00, 38.47it/s]
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
torch.Size([3, 64, 64])
Epoch 1:   3%|██▍                                                                              | 7/232 [00:01<00:34,  6.53it/s, loss=0.918, v_num=wmix]
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.








Epoch 1:  52%|█████████████████████████████████████████▏                                     | 121/232 [00:16<00:14,  7.43it/s, loss=0.887, v_num=wmix]
/mnt/nfs/rdata02-users/users/makaroff/UNet2D/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")